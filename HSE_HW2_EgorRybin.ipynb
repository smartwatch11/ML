{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HSE-HW2-EgorRybin.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQTgBWwLJdOz/t9EdKJkZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartwatch11/ML/blob/main/HSE_HW2_EgorRybin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INoK_776lR_q"
      },
      "outputs": [],
      "source": [
        "# Importing the required library for data processing, works with CSV file\n",
        "import pandas as pd\n",
        "\n",
        "# Reading the dataset\n",
        "df = pd.read_csv('books_train.csv', error_bad_lines=False)\n",
        "# Rename column with bad spaces\n",
        "df.rename(columns={\"  num_pages\":\"num_pages\"}, inplace=True)\n",
        "\n",
        "\n",
        "# Unify the langauge codes\n",
        "encoding = {'language_code':{'en-US': 'eng', 'en-GB': 'eng', 'en-CA': 'eng'}}\n",
        "df.replace(encoding, inplace=True)\n",
        "# Encode categorical features as an integer array\n",
        "enc = OrdinalEncoder()\n",
        "enc.fit(df[['language_code']])\n",
        "# Apply ordinal encoding on language_code to convert it into numerical column\n",
        "df[['language_code']] = enc.fit_transform(df[['language_code']]) \n",
        "\n",
        "# Convert data type of publication_date from object into date type\n",
        "df['publication_date'] = pd.to_datetime(df['publication_date'], format='%m/%d/%Y', errors='coerce')\n",
        "# Extract year of publication in a separate column\n",
        "df['year'] = pd.DatetimeIndex(df['publication_date']).year\n",
        "# Add a new feature which has the number of occurences of each book\n",
        "df['num_occ'] = df.groupby('title')['title'].transform('count') \n",
        "\n",
        "# creating the future Y_TRAIN massive with average_rating and deleting non-numerical features\n",
        "label = df['average_rating'].values\n",
        "df.drop(['bookID', 'title', 'authors', 'isbn', 'isbn13', 'publication_date', 'publisher', 'average_rating'], axis=1, inplace=True)\n",
        "\n",
        "# Split the Data into 70% - 30%\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, label, test_size=0.3)\n",
        "\n",
        "# after that I studied many various code (models) for this dataset on the Internet\n",
        "# and just tryied to chouse the best model, this turned out to be RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "parameters = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'max_depth': [3, 5, 7, 10, 12, 15],\n",
        "    'min_samples_split': [5, 10, 15],\n",
        "    'min_samples_leaf': [5, 10, 15]\n",
        "}\n",
        "#cv - Determines the cross-validation splitting strategy.\n",
        "grad_rf = GridSearchCV(model, parameters, refit=True, cv=10)\n",
        "# Train the model\n",
        "grad_rf.fit(X_train, y_train)\n",
        "\n",
        "# reading test dataset\n",
        "dft = pd.read_csv('books_test.csv', error_bad_lines=False)\n",
        "\n",
        "# do the same manipulations as with the training dataset\n",
        "dft.rename(columns={\"  num_pages\":\"num_pages\"}, inplace=True)\n",
        "encoding1 = {'language_code':{'en-US': 'eng', 'en-GB': 'eng', 'en-CA': 'eng'}} # Unify the langauge codes\n",
        "dft.replace(encoding1, inplace=True)\n",
        "enc1 = OrdinalEncoder()\n",
        "enc1.fit(dft[['language_code']])\n",
        "dft[['language_code']] = enc1.fit_transform(dft[['language_code']]) \n",
        "dft['publication_date'] = pd.to_datetime(dft['publication_date'], format='%m/%d/%Y', errors='coerce') \n",
        "dft['year'] = pd.DatetimeIndex(dft['publication_date']).year \n",
        "dft['num_occ'] = dft.groupby('title')['title'].transform('count')\n",
        "\n",
        "# save bookID in separate array, so that after writing it to a file\n",
        "bookID = dft['bookID'].values\n",
        "dft.drop(['bookID', 'title', 'authors', 'isbn', 'isbn13', 'publication_date', 'publisher'], axis=1, inplace=True)\n",
        "\n",
        "#predict average_rating for test dataset on the trained model\n",
        "test_ratings = grad_rf.predict(dft)\n",
        "\n",
        "# and write it to a file\n",
        "with open('file.txt', 'w') as fw:\n",
        "    fw.write('bookID,average_rating'+'\\n')\n",
        "    for i in range(len(bookID)):\n",
        "        fw.write(str(bookID[i])+','+str(test_ratings[i])+'\\n')"
      ]
    }
  ]
}